{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f3a8fb",
   "metadata": {},
   "source": [
    "# Task 1 — BERT News Topic Classifier\n",
    "\n",
    "AG News → BERT fine-tuning using Hugging Face `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18e4e7",
   "metadata": {},
   "source": [
    "## 1) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53925bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('ag_news')\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47e265",
   "metadata": {},
   "source": [
    "## 2) Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)\n",
    "\n",
    "# AG News has 'text' and 'label'\n",
    "encoded = ds.map(tokenize, batched=True)\n",
    "encoded = encoded.remove_columns(['text'])\n",
    "encoded = encoded.rename_column('label','labels')\n",
    "encoded.set_format('torch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa2dcf",
   "metadata": {},
   "source": [
    "## 3) Prepare model & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acdcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "metric_acc = evaluate.load('accuracy')\n",
    "metric_f1 = evaluate.load('f1')\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir='./outputs',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        'accuracy': metric_acc.compute(predictions=preds, references=labels)['accuracy'],\n",
    "        'f1_macro': metric_f1.compute(predictions=preds, references=labels, average='macro')['f1']\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=encoded['train'],\n",
    "    eval_dataset=encoded['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6d586",
   "metadata": {},
   "source": [
    "## 4) Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaac860",
   "metadata": {},
   "source": [
    "## 5) Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f50aa8",
   "metadata": {},
   "source": [
    "## 6) Inference helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "def predict(text):\n",
    "    return pipe(text)\n",
    "\n",
    "predict('Stocks rally as market optimism grows')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
